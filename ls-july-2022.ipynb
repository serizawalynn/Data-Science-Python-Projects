{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# June 2022 Kaggle Competition Notebook\nThis is my notebook that I will use for the June 2022 Kaggle Competition. It has been a while since I participated in one of these.","metadata":{}},{"cell_type":"markdown","source":"## Step 0: Setup\nHere, I will import libraries such as numpy, pandas, specific functions from sklearn, and the os module that the Kaggle notebooks use. ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T17:23:45.659261Z","iopub.execute_input":"2022-06-29T17:23:45.660016Z","iopub.status.idle":"2022-06-29T17:23:47.595346Z","shell.execute_reply.started":"2022-06-29T17:23:45.659881Z","shell.execute_reply":"2022-06-29T17:23:47.591639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Get the data\nHere, I turned the provided data and sample submission into a pandas dataframe. I will also use some basic methods to peek into the data.","metadata":{}},{"cell_type":"code","source":"#Make a dataframe from the csv file containing the data.\ndf=pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\n\n#Print the first few rows of the dataframe.\nprint(df.head())\n\n#Print the unique data types used in the dataframe.\nprint(df.dtypes.unique())\n\n#Make another dataframe from the sample submission csv file.\nsample_sub=pd.read_csv(\"../input/tabular-playground-series-jun-2022/sample_submission.csv\")\n\n#Print the first ten rows of the sample submission dataframe.\nprint(sample_sub.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:23:53.020351Z","iopub.execute_input":"2022-06-29T17:23:53.020712Z","iopub.status.idle":"2022-06-29T17:24:14.357498Z","shell.execute_reply.started":"2022-06-29T17:23:53.020684Z","shell.execute_reply":"2022-06-29T17:24:14.356104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:53:12.399831Z","iopub.execute_input":"2022-06-28T16:53:12.401498Z","iopub.status.idle":"2022-06-28T16:53:15.695603Z","shell.execute_reply.started":"2022-06-28T16:53:12.401443Z","shell.execute_reply":"2022-06-28T16:53:15.694462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Build Submission DataFrame\nIn the step above, I saw that the row-col column for the sample submission has values in the following format:\n(Row Number)-(Column Name)\nTherefore, it is clear that I need to build a column for my submission csv that indicates the row and column name for the missing values.","metadata":{}},{"cell_type":"code","source":"#Get column names.\ncol_names=df.columns\n\n#Turn the column names array into a list.\ncol_names=list(col_names)\n\n#Remove the first column as it is an index containing row ids.\ncol_names.pop(0)\n\n#Find the index locations of every null value in every column.\n\n#Find the number of columns.\nnum_of_cols=len(df.columns)\n\n#Make a list that contains an empty list for each of the columns in the dataframe.\ncol_missing_lists=[[] for i in range(len(df.columns)-1)]\n\n#Iterate through each column and append the indexes where the value is null.\nfor i in range(len(col_names)):\n    col_missing_lists[i]=df[df[col_names[i]].isnull()].index.to_list()\n\n#Make a list for the row-col values.\nls_submission_rc=[]\n\n# For each column, for each index in the list of indexes for missing data in that column, append a string \n# that follows the (Row)-(Column Name) format for each missing entry.\nfor i in range(len(col_names)):\n    for j in col_missing_lists[i]:\n        ls_submission_rc.append(str(j)+'-'+col_names[i])\n        \n#Make a new dataframe for submission.\nls_submission=pd.DataFrame({\"row-col\":ls_submission_rc})\nprint(ls_submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:24:19.135866Z","iopub.execute_input":"2022-06-29T17:24:19.136291Z","iopub.status.idle":"2022-06-29T17:24:21.611689Z","shell.execute_reply.started":"2022-06-29T17:24:19.136246Z","shell.execute_reply":"2022-06-29T17:24:21.61008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(col_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T00:30:51.992272Z","iopub.execute_input":"2022-06-28T00:30:51.992992Z","iopub.status.idle":"2022-06-28T00:30:51.999485Z","shell.execute_reply.started":"2022-06-28T00:30:51.992948Z","shell.execute_reply":"2022-06-28T00:30:51.997937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check to see if the values in ls_submission are the null values in the original dataframe.","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Impute missing values\nHere, we need to decide which methods to use for data imputation. From the compeition page, we are told that the data, \"...contains missing values due to electronic errors.\" This means that the missing data is missing at random. Here, we are given a reason why there are errors in the dataframe (electronic errors). Based on the type of missing data, I will utilize sklearn's iterative imputer, since it is appropriate for handling missing data that is missing at random. \nI will start with the Iterative Imputer.","metadata":{}},{"cell_type":"code","source":"# Make a copy of the submission dataframe.\nls_submission_ii=ls_submission\n\n# Initiate the iterative imputer.\nimp=IterativeImputer(max_iter=10,random_state=0,tol=1e-8)\n\n# Make a copy of the original dataframe.\ndf1=df[col_names]\n\n# Fit the imputer on the dataframe.\nimp.fit(df1)\n\n# Transform the data.\ndf_imp=imp.transform(df1)\ndf_imp=pd.DataFrame(df_imp,columns=col_names)\n\n# Create a new list for the imputed values.\nii_list=[]\n\n# Find the imputed values corresponding to the cells that are null.\nfor i in range(len(col_names)):\n    for j in col_missing_lists[i]:\n        ii_list.append(df_imp[col_names[i]].iloc[j])\n        \n# Make a new column in the submission dataframe that has our values.\nls_submission_ii[\"value\"]=ii_list\n\n# Output a CSV for Submission\nls_submission_ii.to_csv('ls_submission_ii',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:24:25.458458Z","iopub.execute_input":"2022-06-29T17:24:25.45896Z","iopub.status.idle":"2022-06-29T17:24:45.109733Z","shell.execute_reply.started":"2022-06-29T17:24:25.458928Z","shell.execute_reply":"2022-06-29T17:24:45.107616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Re-evaluate\nThe iterative imputer submission resulted in a score of 0.98250.\nAfter reading through the sci-kit learn documentation, I realized that I glossed over the iterative imputer's ability to utilize other machine learning algorithms as its estimator. Since we are told that the continuous features are the only features that have missing values, we need an estimator that takes in and outputs continuous numeric data. I tried the linear regression and SGDRegressor as my estimator.","metadata":{}},{"cell_type":"markdown","source":"### Step 4A: Linear Regression","metadata":{}},{"cell_type":"code","source":"# Make a copy of the submission dataframe.\nls_submission_ii_LR=ls_submission\n\n# Initiate the iterative imputer.\nimp_LR=IterativeImputer(estimator=LinearRegression(),max_iter=10,random_state=0,tol=1e-8)\n\n# Make a copy of the original dataframe.\ndf1=df[col_names]\n\n# Fit the imputer on the dataframe.\nimp_LR.fit(df1)\n\n# Transform the data.\ndf_imp_LR=imp_LR.transform(df1)\ndf_imp_LR=pd.DataFrame(df_imp_LR,columns=col_names)\n\n# Create a new list for the imputed values.\nii_LR_list=[]\n\n# Find the imputed values corresponding to the cells that are null.\nfor i in range(len(col_names)):\n    for j in col_missing_lists[i]:\n        ii_LR_list.append(df_imp_LR[col_names[i]].iloc[j])\n        \n# Make a new column in the submission dataframe that has our values.\nls_submission_ii_LR[\"value\"]=ii_LR_list\n\n# Output a CSV for Submission\nls_submission_ii_LR.to_csv('ls_submission_ii_LR',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T17:24:50.415762Z","iopub.execute_input":"2022-06-29T17:24:50.416232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4B: SGDRegressor","metadata":{}},{"cell_type":"code","source":"# Make a copy of the submission dataframe.\nls_submission_ii_SGD=ls_submission\n\n# Initiate the iterative imputer.\nimp_SGD=IterativeImputer(estimator=SGDRegressor(),max_iter=10,random_state=0,tol=1e-8)\n\n# Make a copy of the original dataframe.\ndf1=df[col_names]\n\n# Fit the imputer on the dataframe.\nimp_SGD.fit(df1)\n\n# Transform the data.\ndf_imp_SGD=imp_SGD.transform(df1)\ndf_imp_SGD=pd.DataFrame(df_imp_SGD,columns=col_names)\n\n# Create a new list for the imputed values.\nii_SGD_list=[]\n\n# Find the imputed values corresponding to the cells that are null.\nfor i in range(len(col_names)):\n    for j in col_missing_lists[i]:\n        ii_SGD_list.append(df_imp_SGD[col_names[i]].iloc[j])\n        \n# Make a new column in the submission dataframe that has our values.\nls_submission_ii_SGD[\"value\"]=ii_SGD_list\n\n# Output a CSV for Submission\nls_submission_ii_SGD.to_csv('ls_submission_ii_SGD',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Competition End\nThe following are the results of my submissions:\n\nls_submission_ii_LR\n* Private Score: 0.97939\n* Public Score: 0.98252\n\nls_submission_ii_SGD\n* Private Score: 0.99311\n* Public Score: 0.99662\n\nls_submission_ii\n* Private Score: 0.97937\n* Public Score: 0.98250\n\nClearly, it is not always the case that adding a estimator will increase the accuracy of the imputation. ","metadata":{}}]}